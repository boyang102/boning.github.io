[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Projects",
    "section": "",
    "text": "This is Project 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis is Project 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\n\n\n\nBoning Yang\n\n\nApr 16, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\n\n\n\nBoning Yang\n\n\nApr 16, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/project1/index.html",
    "href": "blog/project1/index.html",
    "title": "This is Project 1",
    "section": "",
    "text": "I cleaned some data\n\n\n\nI analyzed the data\n#| message: false\nlibrary(tidyverse) mtcars |&gt; ggplot(aes(x = wt, y = mpg)) + geom_point()"
  },
  {
    "objectID": "blog/project1/index.html#section-1-data",
    "href": "blog/project1/index.html#section-1-data",
    "title": "This is Project 1",
    "section": "",
    "text": "I cleaned some data"
  },
  {
    "objectID": "blog/project1/index.html#section-2-analysis",
    "href": "blog/project1/index.html#section-2-analysis",
    "title": "This is Project 1",
    "section": "",
    "text": "I analyzed the data\n#| message: false\nlibrary(tidyverse) mtcars |&gt; ggplot(aes(x = wt, y = mpg)) + geom_point()"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Boning Yang",
    "section": "",
    "text": "Here’s a paragraph about me :)"
  },
  {
    "objectID": "blog/project2/index.html",
    "href": "blog/project2/index.html",
    "title": "This is Project 2",
    "section": "",
    "text": "I cleaned some data\n\n\n\nI analyzed the data\n#| message: false\nlibrary(tidyverse) mtcars |&gt; ggplot(aes(x = wt, y = mpg)) + geom_point()"
  },
  {
    "objectID": "blog/project2/index.html#section-1-data",
    "href": "blog/project2/index.html#section-1-data",
    "title": "This is Project 2",
    "section": "",
    "text": "I cleaned some data"
  },
  {
    "objectID": "blog/project2/index.html#section-2-analysis",
    "href": "blog/project2/index.html#section-2-analysis",
    "title": "This is Project 2",
    "section": "",
    "text": "I analyzed the data\n#| message: false\nlibrary(tidyverse) mtcars |&gt; ggplot(aes(x = wt, y = mpg)) + geom_point()"
  },
  {
    "objectID": "blog/MGT495_HW1_.html",
    "href": "blog/MGT495_HW1_.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a large-scaled field experiment to investigate whether the matching donations could affect charitable giving behavior. They sent out 50,000 fundraising letters to potential donors and this experiment contains 50,083 participants.\nEach participant was randomly assigned to a control group or a treatment group.For the control group, the participant would receive a 4-pages fundraising letter, while for the treatment group, participants received a very similar letter but it contains an announcement of matching grant, which is promised by the lead donor in order to match the recipient’s donation. Within the treatment group, there are three further treatments: first, researchers add the matching ratio, which contains 1:1, 1:2, or 1:3 match. It indicates the relationship between donation and match values; second, the highest total matching funds is 25,000, 50,000, and 100,000 dollars; third, there is a suggested donation amount on each letter, including 1x,1.25x, or 1.5x.\nThe overall purpose of this experiment design is to see whether the matching contribute to the increasing in donation overall and whether the larger match ratio is more effective or not. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThis project seeks to replicate their results using the original data."
  },
  {
    "objectID": "blog/MGT495_HW1_.html#introduction",
    "href": "blog/MGT495_HW1_.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a large-scaled field experiment to investigate whether the matching donations could affect charitable giving behavior. They sent out 50,000 fundraising letters to potential donors and this experiment contains 50,083 participants.\nEach participant was randomly assigned to a control group or a treatment group.For the control group, the participant would receive a 4-pages fundraising letter, while for the treatment group, participants received a very similar letter but it contains an announcement of matching grant, which is promised by the lead donor in order to match the recipient’s donation. Within the treatment group, there are three further treatments: first, researchers add the matching ratio, which contains 1:1, 1:2, or 1:3 match. It indicates the relationship between donation and match values; second, the highest total matching funds is 25,000, 50,000, and 100,000 dollars; third, there is a suggested donation amount on each letter, including 1x,1.25x, or 1.5x.\nThe overall purpose of this experiment design is to see whether the matching contribute to the increasing in donation overall and whether the larger match ratio is more effective or not. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThis project seeks to replicate their results using the original data."
  },
  {
    "objectID": "blog/MGT495_HW1_.html#data",
    "href": "blog/MGT495_HW1_.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\nI conduct t-tests and simple linear regression models on three selected variables: mrm2, which is the months since last donation; hpa, which is the highest previous contribution; and female, which is a gender indicator with value 1 equal to female. The formula is like what I learned from the class.\nT-test shows as below:\n\n# conduct t-test for selected varaibles above\nt.test(mrm2 ~ treatment, data = data)\n\n\n    Welch Two Sample t-test\n\ndata:  mrm2 by treatment\nt = -0.11953, df = 33394, p-value = 0.9049\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -0.2381015  0.2107298\nsample estimates:\nmean in group 0 mean in group 1 \n       12.99814        13.01183 \n\nt.test(hpa ~ treatment, data = data)\n\n\n    Welch Two Sample t-test\n\ndata:  hpa by treatment\nt = -0.97043, df = 35914, p-value = 0.3318\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -1.9238107  0.6496601\nsample estimates:\nmean in group 0 mean in group 1 \n       58.96017        59.59724 \n\nt.test(female ~ treatment, data = data)\n\n\n    Welch Two Sample t-test\n\ndata:  female by treatment\nt = 1.7535, df = 32451, p-value = 0.07952\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -0.0008888548  0.0159826921\nsample estimates:\nmean in group 0 mean in group 1 \n      0.2826978       0.2751509 \n\n\nlinear regression shown as below:\n\nlibrary(broom)\n\nWarning: package 'broom' was built under R version 4.3.3\n\nlibrary(knitr)\n\nWarning: package 'knitr' was built under R version 4.3.3\n\nlibrary(dplyr)\n\nmodels &lt;- list(\"Months since last donation\" = lm(mrm2 ~ treatment, data = data),\n  \"Highest previous amount\" = lm(hpa ~ treatment, data = data),\n  \"Female indicator\" = lm(female ~ treatment, data = data))\n\nmodel_output &lt;- lapply(names(models), function(name) {\n  broom::tidy(models[[name]]) %&gt;%mutate(p.value = format.pval(p.value, digits = 5)) %&gt;%\n    mutate(model = name)}) %&gt;%bind_rows()\n\nmodel_output %&gt;%\n  select(model, term, estimate, std.error, statistic, p.value) %&gt;%\n  knitr::kable(digits = 3, caption = \"balance check regressions\")\n\n\nbalance check regressions\n\n\n\n\n\n\n\n\n\n\nmodel\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\nMonths since last donation\n(Intercept)\n12.998\n0.094\n138.979\n&lt; 2e-16\n\n\nMonths since last donation\ntreatment\n0.014\n0.115\n0.119\n0.90489\n\n\nHighest previous amount\n(Intercept)\n58.960\n0.551\n107.005\n&lt;2e-16\n\n\nHighest previous amount\ntreatment\n0.637\n0.675\n0.944\n0.3451\n\n\nFemale indicator\n(Intercept)\n0.283\n0.004\n80.688\n&lt; 2e-16\n\n\nFemale indicator\ntreatment\n-0.008\n0.004\n-1.758\n0.078691"
  },
  {
    "objectID": "blog/MGT495_HW1_.html#experimental-results",
    "href": "blog/MGT495_HW1_.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\nThe interpretation of the results:\nThrough running the t-test, I find the following results:\n•   mrm2: mean (control): 12.998, mean (treatment): 13.012, t = -0.120, p = 0.905; It indicates not statistically significant.\n•   hpa: mean (control): 58.96, mean (treatment): 59.60, t = -0.970, p = 0.332; It indicates not statistically significant.\n•   female: mean (control): 28.3%, mean (treatment): 27.5%, t = 1.754, p = 0.080; It indicates not significant.\nThe results I obtain from t-test validate that the random assignment created statistically comparable groups; all of the p-value is above the 0.05 threshold, which indicates we can not reject the null hypothesis.\nThe results connect to the Table 1 in the paper (Karlan and List, 2007) and show the randomization works as intended and could use to explain the outcome differences in later parts due to the treatments not the imbalance in baseline.\nI use the linear regression part to validate my result from t-test. I run the linear regression model on the same variables and find the following results:\n• mrm2:estimated difference: 0.0137 months, p = 0.905; indicates no significant difference.\n•   hpa: estimated difference: 0.6371 dollars, p = 0.345; indicates no significant difference.\n•   female: estimated difference: -0.0075 (0.75 percentage points fewer women in treatment), p = 0.079; indicates no significant.\nThe results I obtain from linear regression model is similar to the ones I obtain from t-test; none of them are significant difference at 0.05 level.\nBoth t-test and linear regression models yield similar results, which confirm that the group are well-balanced before the experiment started. It supports the internal validity of the design of experiment as shown in the table 1 in Karlan and List(2007) paper. It indicates any outcome downstream differences can be explained to the treatment assignment.\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation. This is like the table 2 panel A shown in the paper.\n\n# use ggplot\nlibrary(ggplot2)\nlibrary(scales)\n\n# group means\ndonate_rate &lt;- data %&gt;% group_by(treatment) %&gt;% summarise(proportion = mean(gave, na.rm = TRUE))\n\n# convert treatment to factor to label\ndonate_rate$treatment &lt;- factor(donate_rate$treatment, labels = c(\"control\", \"treatment\"))\ndonate_rate$label &lt;- paste0(round(donate_rate$proportion * 100, 1), \"%\")\n\n# visualize using barplot\nggplot(donate_rate, aes(x = treatment, y = proportion, fill = treatment)) +\n  geom_bar(stat = \"identity\", width = 0.6) +geom_text(aes(label = label), vjust = -0.5, size = 5)+\n  labs(title = \"donation rate by treatment group\",x = \"group\",y =\"proportion donated\") +\n  scale_y_continuous(labels = percent_format(accuracy = 0.1), limits = c(0, max(donate_rate$proportion) + 0.01))+theme_minimal()\n\n\n\n\n\n\n\n\nNow, it is important to identify if the individuals in treatment group are more likely to make donations than the ones in control group, now run a t-test and linear regression on the binary outcomes.\n\n# t-test\nt.test(gave ~ treatment, data = data)\n\n\n    Welch Two Sample t-test\n\ndata:  gave by treatment\nt = -3.2095, df = 36577, p-value = 0.001331\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -0.006733310 -0.001627399\nsample estimates:\nmean in group 0 mean in group 1 \n     0.01785821      0.02203857 \n\n\n\n#linear regression\nmodel_gave &lt;- lm(gave ~ treatment, data = data)\nmodel_gave_output &lt;- tidy(model_gave)\nmodel_gave_output %&gt;%\n  select(term, estimate, std.error, statistic, p.value) %&gt;%\n  knitr::kable(digits =4, caption = \"Regression:treatment effect on donation rate\")\n\n\nRegression:treatment effect on donation rate\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n0.0179\n0.0011\n16.2246\n0.0000\n\n\ntreatment\n0.0042\n0.0013\n3.1014\n0.0019\n\n\n\n\n\nThe results I get from two sample t-test is:\n•   mean in control group: 1.79%\n•   mean in treatment group: 2.20%\n•   difference in means: 0.42 percentage points\n•   p-value: 0.0013\nSince p-value is 0.0013, which indicates the difference is statistically significant at the 1% level.\nThe results I get from linear regression is: • control group mean: 0.0179 • treatment coefficient: 0.00418 • p-value: 0.0019\nThe estimate above of linear regression confirms the t-test result, which indicates individuals in the treatment group are 0.42% more likely to donate.\nOverall, both results show that receiving a matching grant offer could improve the giving probability, which confirms the finding in table 2 panel A in the paper. It could support the idea that people could respond to perceived impact.\nTo further prove the finding, I run probit regression. The independent variable here is treatment and depend variable is whether the person donate, which replicates the result in table 2 column 1 from original paper.\n\n# probit model:\nprobit_model &lt;- glm(gave ~ treatment, data = data, family = binomial(link = \"probit\"))\nprobit_output &lt;- tidy(probit_model)\n\nprobit_output %&gt;%\n  select(term, estimate, std.error, statistic, p.value) %&gt;%\n  knitr::kable(digits = 4, caption = \"Probit model\")\n\n\nProbit model\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-2.1001\n0.0233\n-90.0739\n0.0000\n\n\ntreatment\n0.0868\n0.0279\n3.1130\n0.0019\n\n\n\n\n\nThe output I get from probit model:\n•   intercept is -2.100\n•   treatment coefficient is 0.087\n•   p-value is 0.0019\nThe treatment coefficient is 0.087, which indicates receiving a matching offer could increase the giving probability. It also confirms the previous conclusion.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate. I constrain the sample to treatment group and use pairwise t-test:\n\n#t-test between 2:1 and 1:1\ntreatment_only &lt;- filter(data, treatment == 1) #treatment group subset\ngave_ratio1 &lt;- filter(treatment_only, ratio == 1)$gave #ratio group\ngave_ratio2 &lt;- filter(treatment_only, ratio == 2)$gave\ngave_ratio3 &lt;- filter(treatment_only, ratio == 3)$gave\nt.test(gave_ratio2, gave_ratio1)\n\n\n    Welch Two Sample t-test\n\ndata:  gave_ratio2 and gave_ratio1\nt = 0.96505, df = 22225, p-value = 0.3345\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.001942773  0.005711275\nsample estimates:\n mean of x  mean of y \n0.02263338 0.02074912 \n\n\n\n#t-test between 3:1 and 1:1\nt.test(gave_ratio3, gave_ratio1)\n\n\n    Welch Two Sample t-test\n\ndata:  gave_ratio3 and gave_ratio1\nt = 1.015, df = 22215, p-value = 0.3101\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.001847501  0.005816051\nsample estimates:\n mean of x  mean of y \n0.02273340 0.02074912 \n\n\n\n#t-test between 3:1 and 2:1\nt.test(gave_ratio3, gave_ratio2)\n\n\n    Welch Two Sample t-test\n\ndata:  gave_ratio3 and gave_ratio2\nt = 0.050116, df = 22261, p-value = 0.96\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.003811996  0.004012044\nsample estimates:\n mean of x  mean of y \n0.02273340 0.02263338 \n\n\nFor the first comparison, which is 2:1 to 1:1 case, the mean response rate o9f 2:1 is about 2.26% and mean response rate of 1:1 is about 2.07%, p-value in this case is 0.335, which is not significant at level 0.05; for the second case, which is 3:1 to 1:1 match case, the mean response rate for 3:1 is 2.27% and for 1:1 is 2.07%, and p-value is 0.310, which indicates not significant at level 0.05; for the third case, mean response rate for 3:1 is 2.27% and for 2:1 is 2:26%. Across all three comparison, the donation rate is pretty small and not significant. This support the page 8 of the paper where the author mentions “….figures suggest that increasing the match ratio from 1:1 to 2:1 or 3:1 does not increase the likelihood of giving.” (Karlan and List, 2007). It indicates that announcing match does not play a role in affecting the donation rate and increasing match ratio beyond 1:1 seems not contribute to boost donation.The match matters more than the size.\nNow, I assess the same issue using a regression. I create dummy variables for each match ratio within the treatment group (ratio1, ratio2, and ratio3). If include all the three groups, I will have a multicollinearity, soo I exclude ratio 1 and make it as a reference group, which allows ratio2 and ratio3 to be explained as differences to 1:1 match.\n\n# regression\nmodel_dummies &lt;- lm(gave ~ ratio2 + ratio3, data = treatment_only)\nmodel_dummies_output &lt;- tidy(model_dummies)\n\n# clean table\nmodel_dummies_output %&gt;%\n  select(term, estimate, std.error, statistic, p.value) %&gt;%\n  knitr::kable(digits = 4, caption = \"Regression: differences across match ratios\")\n\n\nRegression: differences across match ratios\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n0.0207\n0.0014\n14.9122\n0.0000\n\n\nratio2\n0.0019\n0.0020\n0.9576\n0.3383\n\n\nratio3\n0.0020\n0.0020\n1.0083\n0.3133\n\n\n\n\n\nThe results of the regression shows the intercept 0.02075 represents the mean donation for 1:1 match group; coefficient for ratio2 is about 0.00188 and has 0.19% increase. It is not significant since p=0.338 which is above 5% level. The coefficient for ratio3 is abou 0.00198 and is still not significant at the 5% level (p-value is 0.313).\nThe results I get here are consistent with the early calculation using t-test, which confirm the paper’s perspective on 8 page.\nTo calculate the response rate difference between the 1:1 and 2:1 match ratios and 2:1 and 3:1 ratios, I need to use raw group means and regression coefficients to compare:\n\n# find the group mean response rates\ntreatment_only &lt;- filter(data, treatment == 1)\ngroup_rates &lt;- treatment_only %&gt;%\n  group_by(ratio) %&gt;%\n  summarise(rate = mean(gave))\n\ngroup_rates\n\n# A tibble: 3 × 2\n  ratio       rate\n  &lt;dbl+lbl&gt;  &lt;dbl&gt;\n1 1         0.0207\n2 2         0.0226\n3 3         0.0227\n\n\n\n#for regression coefficients:\nmodel_dummies &lt;- lm(gave ~ ratio2 + ratio3, data = treatment_only)\n\nmodel_amount_output &lt;- tidy(model_dummies)\n\nmodel_amount_output %&gt;%\n  select(term, estimate, std.error, statistic, p.value) %&gt;%\n  knitr::kable(digits = 4, caption = \"Regression: treatment effect on donation amount\")\n\n\nRegression: treatment effect on donation amount\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n0.0207\n0.0014\n14.9122\n0.0000\n\n\nratio2\n0.0019\n0.0020\n0.9576\n0.3383\n\n\nratio3\n0.0020\n0.0020\n1.0083\n0.3133\n\n\n\n\n\nFrom the results I obtained above, both methods shows that from 1:1 to 2:1, it has a small increase in giving; 2:1 to 3:1 shows no additional benefits with only 0.01% increased. This further confirmed the argument in the paper on page 8 where the author mentions \"figures suggest that increasing the match ratio from 1:1 to 2:1 or 3:1 does not increase the likelihood of giving\".\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\nTo further see if the macth donations would influence the size of charitable contribution, I use a t-test to compare between the treatment and control group:\n\n#choose do a t-test\nt.test(amount ~ treatment, data = data)\n\n\n    Welch Two Sample t-test\n\ndata:  amount by treatment\nt = -1.9183, df = 36216, p-value = 0.05509\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -0.310555423  0.003344493\nsample estimates:\nmean in group 0 mean in group 1 \n      0.8132678       0.9668733 \n\n\nIt shows that the average for control group is 0.813 and for treatment group is 0.967, difference is about 0.154 and p-value is about 0.055, which is not significant at 5% level. It is very close to 5% and could suggest there is a positive relationship. This result further reinforces that match offers increase participation.\nNow, limit the data to just people who made a donation and repeat the previous analysis. This regression allows us to analyze how much respondents donate conditional on donating some positive amount.\n\n#only keep data with donation\ndonated_only &lt;- filter(data, amount &gt; 0)\n\n# regression analysis\nmodel_donation_only &lt;- lm(amount ~ treatment, data = donated_only)\nmodel_amount_output &lt;- tidy(model_donation_only)\nmodel_amount_output %&gt;%\n  select(term, estimate, std.error, statistic, p.value) %&gt;%\n  knitr::kable(digits = 4, caption = \"Regression: treatment effect on donation amount\")\n\n\nRegression: treatment effect on donation amount\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n45.5403\n2.4234\n18.7921\n0.0000\n\n\ntreatment\n-1.6684\n2.8724\n-0.5808\n0.5615\n\n\n\n\n\nAfter I dive into the people who donate, the result shows that the treatment group has 1.67 dollar less on average. The p value here is 0.5615, which larger than 5% level and it is not significant. It indicates match offer encourages people to donate but it does not change the amount of values they give. I cannot interpret it causally since it only contains the donors.\nThen I make plots: one for the treatment group and one for the control. Each plot is a histogram of the donation amounts only among people who donated. I add a red vertical bar to indicate the sample average for each plot.\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\ndonated &lt;- data %&gt;% filter(gave == 1) #only keep people who make donation\n\n# 0 = control, 1 = treatment\ndonated &lt;- donated %&gt;% mutate(treatment = factor(treatment, levels = c(0, 1), labels = c(\"control\", \"treatment\")))\n#avg donation\navg_amounts &lt;- donated %&gt;%group_by(treatment) %&gt;%summarise(mean_amount = mean(amount, na.rm = TRUE))\n\n#visualize uisng histogram\nggplot(donated, aes(x = amount)) +\n  geom_histogram(binwidth = 4,color = \"blue\") +facet_wrap(~treatment, scales = \"free_y\") +\n  geom_vline(data = avg_amounts, aes(xintercept = mean_amount), color = \"red\", linetype = \"dashed\") +\n  labs( x = \"donation ($)\", y = \"count\") +theme_minimal()"
  },
  {
    "objectID": "blog/MGT495_HW1_.html#simulation-experiment",
    "href": "blog/MGT495_HW1_.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\nset.seed(1)\n\n#simulate 100,000 draws for control with p = 0.018 and for treatment with p = 0.022\ncontrols &lt;- rbinom(100000, 1, 0.018)\ntreatments &lt;- rbinom(100000, 1, 0.022)\n\n#differences\ndif&lt;- treatments - controls\n#cumulative average\ncum_avg &lt;- cumsum(dif) / seq_along(dif)\n\n#visualize\nggplot(data.frame(n = 1:100000, cum_avg = cum_avg), aes(x = n, y = cum_avg)) +\n  geom_line(color = \"blue\") +geom_hline(yintercept = 0.004, color = \"red\") +\n  labs(title = \"cumulative average using LLN\",x = \"simulations\",\n    y =\"cumulative average of differences\") +theme_minimal()\n\n\n\n\n\n\n\n\nFrom the graph above, I could see how the cumulative average of differences changes with the increasing in simulations. As simulations increases, the cumulative average of differences converge to 0.004, which shows me the Law of Large Numbers. This reflects a very useful thing that demonstrates the empirical estimates made not due to random noise and could approach the true means.\n\n\nCentral Limit Theorem\nThen, I make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000.\nTo do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Then I plot the histogram of those averages.\n\nset.seed(1)\nlibrary(tibble)\n\n# function\nsimulate_diff &lt;- function(n, reps = 1000, p1= 0.018, p2 = 0.022) {\n  replicate(reps, {control &lt;- rbinom(n, 1, p1)\n  treatment &lt;- rbinom(n, 1, p2)\n  mean(treatment) - mean(control)})}\n\ndiff_50 &lt;- simulate_diff(50) #sample size\ndiff_200 &lt;- simulate_diff(200)\ndiff_500 &lt;- simulate_diff(500)\ndiff_1000 &lt;- simulate_diff(1000)\n\ndf &lt;- tibble(diff = c(diff_50, diff_200, diff_500, diff_1000),\n  n = factor(rep(c(50, 200, 500, 1000), each = 1000),levels = c(50, 200, 500, 1000)))\n#plot\nggplot(df, aes(x = diff)) +geom_histogram(binwidth = 0.01, fill = \"blue\") +\n  facet_wrap(~ n, scales = \"free_y\") +geom_vline(xintercept = 0, color=\"red\") +\n  labs(title = \"sampling distribution of average differences\",\n    x = \"average difference (treatment - control)\", y = \"count\") +theme_minimal()"
  }
]